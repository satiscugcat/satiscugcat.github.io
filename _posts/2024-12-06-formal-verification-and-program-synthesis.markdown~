---
layout: post
title: "Winter School on Formal Vertification and Program Synthesis, IIT Delhi"
---
# Table of Contents #
1. [**Day 1**](#day1)
   1. [**Talk by Prof Sanjam Garg on his Research Journey**](#sanjam)
   2. [**Lecture by Subodh Sharma on Symbolic Execution: Fundamentals and Applications**](#symbolic)
2. [**Day 2**](#day2)
   1. [**Talk by Ravindra Metta on Formal Verification and Synthesis at TCS Research**](#tcs)
   2. [**Lecture+Tutorial by Aalok Thakkar on Introduction to Enumerative Synthesis**](#as)
   3. [**Lecture by Kumar Madhukar on Neural Network Verification Part I**](#dnn)
3. [**Day 3**](#day3)
   1. [**Lecture by Kumar Madhukar on Neural Network Verification Part II**](#dnn2)
   2. [**Talk by Silvia Ghilezan Proofs as Programming Paradigms: From Logic to AI**](#lambda)
   3. [**Tutorial by Priyanka Golia on SAT Solvers Part I**](#sat)
4. [**Day 4**](#day4)
   1. [**Tutorial by Priyanka Golia on SAT Solvers Part II**](#sat2)
   2. [**Invited Lecture**](#inv)
   3. [**A Final Interaction**](#end)
# Day 1 <a name="day1"></a> #

## Talk by Prof Sanjam Garg on his Research Journey <a name="sanjam"></a> ##

We began the day with a presentation by [Prof. Sanjam Garg](https://people.eecs.berkeley.edu/~sanjamg/) of UC Berkeley and alumnus of IITD, about his learnings as a researcher, titled **"Your Research Career"**. (His presentation largely drew fron ["You and Your Research" by Richard Hamming](https://www.cs.virginia.edu/~robins/YouAndYourResearch.html)). 

For him, the main motivating question for cryptography has been, "What is Possible?", how can you encrypt, how can you work with encrypted data, etc. Success over the past two decades has included FHE, Obfuscation, etc. However, following success, it becomes necessary to move into newer directions (quantum computers, real world needs, practical efficiency), constantly asking, "What is Possible?". Now, how does one make progress in answering that question? For him, the most important question a researcher should ask themselves is "What are the most important problems in my field?". At the end of the day, a researcher is responsible for their own career, their advisor is just their advisor. The question of what an important problem is thus something every researcher should ask for themselves, considering various variable factors such as location, timespan, etc.

He emphasises that it is important not to fear. Fear may prevent a reseacher to take on important problems, expecting to waste time, however, most important problems see significant progress in a decade. It's thus important to have courage to work consistently on things that one thinks are difficult and important. He backed his words by showing a lisit of open problems he had jotted down a decage ago. Open problems to which no approach existed at the time which he wrote them. However, most of them turned out to either be solved or have significant progress in the next decade, winning best paper awards in STOC, EUROCRYPT, and CRYPTO. Once a researcher has chosen a problem, he feels that it is important that they take that problem as something to guide them. It is important to find smaller goals to guide oneself to that bigger problem, working persistently in small (publishable steps), working on new techniques and seizing the opportunity when those ideas mature.

He emphasises that it is very important to **communicate technical ideas clearly**. If this is not done, then any results obtained from one's work are prone to be forgotten, giving way for a future researcher to work on the same problem and publish their work again, all because they couldn't understand your work. Communication also allows one to get feedback from other people, letting one get gain new perspectives on the topic. Talking to people a lot is in general something that helps, not only in solving problems, but also in finding opportunities for further exploration. While doing good research is important, it's also good to have fun along the way.

Summary on how to research well
- What is the most important problem of my field?
- Why don't I work on it? If someone will solve it in the next decade?
- Can I make the tiniest progress on this problem?
- Can I expand it to an interesting paper?
- If not, revisit anytime you find a new technique to attack the problem
- The more you work, the bigger the compounding effect

##  Lecture by Subodh Sharma on Symbolic Execution: Fundamentals and Applications <a name="symbolic"></a> ##

### How can we test a program?

**The more traditional approach : Concrete Execution** - Clasically, developers may try to ensure the correctness of their code by writing test cases, where different inputs and expected outputs of a program are jotted down, and the program is run on those inputs and the outputs are checked against those expected outputs. The program passes the tests if all the outputs match all the corresponding expected outputs. However, this approach is not appealing for many reasons. For one, passing test cases does not provide a *guarantee* that the program will work for *all* possible inputs. Even with a simple factorial program, a programmer may forget to account for the cases of negative input or for the case of a large input (which may cause integer overflow). What we would like to do is know *for sure* that all bugs in the program have been caught. How can we go about this?

**A systematic way to test : Symbolic Execution** - In the approach proposed in a paper by JC King in 1976 called **Symbolic Execution and Program Testing**, we do not actually *execute* the program. What we do is to assign the unknown/unfixed variables of the program with *symbols*, which are then traced through the different control flow pathways of the program. In each of these paths, the execution keeps track of the different properties that these symbolic variables have, and then finally checks for a certain criterion at the end of the program. Thus, symbolic execution is useful for guaranteeing state invariant properties, which must hold across all initial states and given inputs (since the symbols and the constraints generated never depend on any *concrete* value, as no actual execution is done). The symbolic execution generates different control flow pathways according to different possible executions given the variability of the symbols. The symbolic execution then generates different constraints for the pathways, called path constraints. These path constraints take the form of first order logic formulas involving the symbols and variables in the program. Let us look at an example.

``` C
int factorial(int n){
	if (n < 0) {
		perr("Error: Negative Input");
		return -1;
	}
	int result = 1;
	for(int i = 1; i<n; i++){
		result *= i;
	}
	return result;
}


int main(){
	int n;
	make_symbolic(&n, sizeof(n), "n");
	int result = factorial(n);
	assert(result >=1 || n<0);
	return result;
}
```

The **Symbolic Execution Engine (SEE)** assigns the symbol $$n_0$$ to the variable *n* (instead of assigning a specific value like concrete execution). On reaching the first conditional, it branches the execution into two paths. In the path  where the conditional is satisfied, it generates the constraint $$n_0 < 0$$ (since this is the condition for the execution to happen) and then exits the function. In the other path, it generates the constraint $$n_0 \ge 0$$. With the assignment and the for loop, the SEE is also able to generate the constraint $$result \ge 1$$. Upon exiting the factorial, in both paths, the SEE then conjuncts the constraint generated on the path with the **negation** of the statement in the assertion (which is the state invariant for the program, since we want the assert to pass regardless of the input or initial state). In the first case, this finally generates the constraint $$n_0 < 0 \land \neg(result \ge 1 \lor n_0 < 1)$$ while it generates the constraint $$n_0 \ge 0 \land result \ge 1 \land \neg(result \ge 1 \lor n_0 < 1)$$. In either case, it is obvious that the final result can never be true, thus the assertion must always pass. Thus we have used symbolic execution to prove the correctness of the program.

Notice what we have done, however. After we negate the state invariant and obtain a first order logic formula over boolean values, we are interested in either showing a case where it turns out to be true (ie. the state invariant doesn't hold for some input or initial state) or showing that it is false regardless of the values of the booleans (ie. the state invariant always holds). Hwever, is nothing but the [Boolean Satisfiability Problem](https://en.wikipedia.org/wiki/Boolean_satisfiability_problem)!!! Thus, we have used Symbolic Execution to reduce the problem of program verification into the well studied SAT problem, for which we can use any existing SAT solver. Not only do we get to know if the program has errors, we also get to know what input would cause an error in the program. This is something that deserves a moment of appreciation. Let us now express these notions a little formally.

For a given program, let $$\sigma$$ represent the symbolic store (as opposed to the usual store a program has) it is a map from the set of variables $$V$$, to the set of symbolic expressions $$SymExp$$. Let $$\mu$$ represent a first order boolean logic formula, where the booleans may contain expressions which may contain both symbols and variables. Let $$pc$$ represent the program counter. The state of the Symbolic Execution Engine can thus be represented as the thruple:

$$\Sigma = (pc, \sigma, \pi)$$

The points of interest lie whenever the program assigns a value or branches. In the case of the assignment, $$x:=e$$ results in the symbolic store getting updated as $$\sigma[x \rightarrow e_s]$$, where $$e_s$$ is the equivalent symbolic expression under $$\sigma$$. In the case of a branching statement of the form   if $$e$$ then $$s_t$$ else $$s_e$$, the SEE maintains the constraint $$\pi \land e_s$$ for the then branch and the constraint $$\pi \land \neg e_s$$ for the else branch.

A state invariant for a program holds if and only if, at the end of every control flow pathway, the boolean formula resulting from $$\pi \land \neg S$$ is **unsatisfiable** (where $$\pi$$ corresponds to the state at the end of the CFP and $$S$$ is the state invariant expressed as a boolean formula). 

### Symbolic Execution in the here and now

The above sections up the basics of Symbolic Execution. In modern applications, it is worth noting that instead of SAT solvers, SMT solvers like Z3, CVC4, and STP are used allowing verification for a wider range of programs (although, there are still troubles with multiplicative expressions and transcendental functions, which are hard to reason with using an automated solver). Aside from that, there are multiple challenges in SEE implementations like

- Memory: How do you handle pointers, arrays, and complex data structures?
- Environment: How do SEEs interact with side effecting system calls or libraries?
- Path Explosion: How to handle programs with a large number of control flow paths? How to handle loops?

One of the key ideas that helps with the last problem is mixing symbolic execution with concrete execution. This popular approach is known as dynamic symbolic execution (or combolic execution), where concrete executions are used to dictate the control flow paths that the symbolic execution would investigate. While this leads to a lack of soundness, the way one implements the SEE can still lead to a large range of effectiveness, allowing one to cover a good majority of cases in practical use. Some such design decisions that can go into the making of an SEE are -
- Control Flow Graph Traversal - Aside from DFS and BFS, one may also traverse the control flow graph by assigning different weights to the different vertices in the graph based on their length from the source or the number of outgoing edges (ie. the number of branching outcomes) at that point and prioritise traversal based on that.
- Online vs Offline executors - One may use an online executors to traverse multiple CFPs in parallel, or an offline executor for a single path at a time
- Adding features for different language constructs - Subodh Sir had mentioned working on SKLEE, a modification of KLEE that allowed support for the kinds of functions used in Solidity to write immutable etherium contracts. Such things can be done for other language constructs.
- Modelling Memory - One way to model memory is Fully Symbolic Memory, where every pointer, every element of an array is considered a symbolic variable. This leads to state forking, where whenever an array is considered with an operation on a variable index, the SEE must consider the possible executions at every possible array location. An alternate approach is using Heap Analysis to figure things out using the shape of the memory in the heap. However, this is an active research problem.

If all of this interests you, you may try your hands on [KLEE](https://klee-se.org/), a symbolic execution engine using the clang LLVM. It is excessively documented, and is easy to install using Docker (and other methods). Play around! You can try the following problems that Sir gave us during the talk if you wish to test your understanding.

**Exercises**
- Write a bubble sort program in C and test the postcondition of the sort using KLEE
- Verify the correctness of Binary Search w.r.t. edge cases $$key < arr[0]$$ or $$key > arr[sz-1]$$.

That is all for Symbolic Execution!

# Day 2 <a name="day2"></a>

## Talk by Ravindra Metta on Formal Verification and Synthesis at TCS Research <a name ="tcs"></a>

### Introduction

We started the day with a talk by [Ravindra Metta](https://www.linkedin.com/in/ravindra-metta-00b2b75/) on his experience with formal methods at TCS research.

Nowadays, while there are many kinds of research branches at TCS research, for AI, Smart Cities, Data Analysis, for him the beginnings of TCS research has always been with program analysis and code verification. He says that in the normal industrial picture, there are only a few places where formal specifications for how programs should behave are even *available*. Most stuff is just chaotic and glued together with API tests, user feedback, other testing scripts, and more. However, when working with critical technologies, like biomedical devices, nuclear fission reactors, or even if you want to ensure that your code does work, he feels the only way forward is by using formal specification and correctness. 

The ultimate goal with formal verification is Autonomous Software Engineering. At TCS Research, people are interested in using formal tools like bounded model checking and PROTON (a termination verifier), along with generative AI techniques to build programs. The formal verification tools builds constraints for the programs to follow, through proofs and tests, for not only fixing buggy programs and generating tests, but also synthesising programs. While, purely logical methods *can* be used for these purposes, for computationally hard problems, they have found success in using genrative AI to guess solutions. The output of this formal verifier can then be used to provide feedback to the generative AI to modify its output.

Another thing they're interested is in partial verification. In the real world there are many applications where code interacts with external code which it has no access to. Thus, TCS research is working on partial verification tools, which try to generate the *maximal* set of constraints that can be applicable to the partial system. There's also work in synthesising bank database queries according to specifications, work in synthesising oracles and tests for insurance policies especially in the context of generating different insurance policies according to the different laws in different regions, and even in ensuring correctness in automative, security, and IoT industries. One of the key takeaways from all this to him, is that formal verification is something that is applicable in many places everywhere. There are many successful industrial applications to be built and many top tier papers and patents to be made.

### A Deeper Look
After giving us a brief summary, he provided us a more detailed walkthrough over the kind of formal verification work TCS Research has been doing across different fields.
- **Requirement Engineering** - Companies tend to provide different written specifications for how code should work, the idea of Requirement Engineering is to be able to automatically convert these written specifications using Natural Language Processors into automata over which formal verification tools could operate. Thus automating the task of generating the test cases according to written specifications.
- **Software Engineering** - In software engineering applications, there's an exponential blow up of possible execution paths. Fo this, the ISO standard (ISO26262) requires MCDC testing for certain critical software. Now, manually writing the tests for MCDC thing is difficult, so using Pushdown Automata, Monotone Flow Analysis, and SAT + SMT solvers, people at TCS Research have developed a tool called AutoGen that has been used to find bugs in a wide variety of code.
- **Hardware Engineering** - They have been very successful at bug hunting in hardware chips using automated tools.
- **Systems Engineering** - In timing sensitive applications, it is of high interest to analyse things such as race conditions and worst case execution times (like the airbag in a car for example). Using Timed Automata, and Hybrid Model Checking, they have developed tool flows that are able to not only generate tighter benchmarks, but also generate actual traces for the runs with worst case execution time.
- **Business Engineering** - An automotive company once gave a problem to TCS research. The problem was that they had different constraints of budget and resources, but figuring out what they could build from this. To solve this resource allocation problem, TCS Research built a solution that converted all these constraints to a boolean logic formula (in Conjunctive Normal Form), and then used a #SAT solver to figure out the number of possible solutions to those resource constraints.
- **Production Engineering** - When giving out cars for test drives, one needs to ask how to allocate those that car for what different tests. Many constraints come up because of this. Tests cannot happen at the same time, must end before due dates, some tests must be done, the tests should start as soon as the car gets manufactured, etc. Plugging these solvers into an SMT solver that also optimises for factors such as minimising the number of vehicles used, has led to upto tens of millions of dollars when this solution was used by a certain company, outperforming their previous solution on both cost and time.

## Lecture+Tutorial by Aalok Thakkar on Introduction to Enumerative Synthesis <a name="as"></a>

A lecture was given by [Aalok Thakkar](https://aalok-thakkar.github.io/) introducing us to the problem of program synthesis along with the solution of enumerative synthesis. He starts with a notion of thinking of program synthesis that converts dreams into programs (as introduced in [this paper](https://ieeexplore.ieee.org/document/1702636) from 1979). Here, dreams are formal specifications representing user intent, and the job of program synthesis is to generate a program that follows this specification (which can be verified by a verification algorithm). One way to describe this specification is by using mathematical specification which while precise, can be complicated. The other is natural language, which while being easy to follow, is much too vague. The area that Aalok is interested in is using input-output examples. Users specify different pairs of inputs and outputs (which can serve both as examples of correct and incorrect behaviour). The input-output problem thus becomes the problem of searching a program that satisfies those input output examples, which also makes it a supervised learning problem.

This raises a challenge however. How do we ensure that our test cases completely capture the behaviour of our program? And how do we ensure that we do not overfit to the examples?

The rest of the session was spent on a tutorial where we tried a problem like this hand on. The problem was, given a set of boolean variables, and given the input-output behaviour of a first order logic formula *f* that returns either a 1 or a 0 for some cases of the input variables, how do you construct the formula for *f* in such a manner that it satisfies all the test cases while minimising the number of logical connectives (OR, NOT, AND) used in the formula? (Try this problem for yourself!) The algorithm showcased in the tutorial was one where first all formulae of size 0 were tried, then all formulae of size 1, then all of size 2, and so on until a valid formula was found (here size is simply the number of logical connectives). This is the approach for enumerative synthesis, and the core idea is to looking into how we could further optimise these kinds of algorithms.

## Lecture by Kumar Madhukar on Neural Network Verification Part I<a name="dnn"></a>

In this talk by [Kumar Madhukar](https://kumarmadhukar.github.io/) of IIT Delhi, to be continued in the following day, we looked at the problem of Deep Neural Network Verification. In traditional program verification, given a program of a certain form we want to be able to prove a ceetain property about it mathematically, or give a counterexample if it does not work. 

```C
int fac(int c){
	int y = 1;
	int z = 0;
	while(z!=x){
		z = z+1;
		y=y*z;
	}
	return y;
}
```
For example, for this program, a simple loop invariant argument holds to prove that if *(x > 0) then fac(x) = x!*, thus we can reason about the factorial program as a mathematical object.

However, how do we this for neural networks? Let us consider the task of recognising digits from images. There is no simple formal rule that can distinguish 2 from 7 in human writing styles, since human writing styles do not follow any easy to understand formal set of rules. This is why we use neural networks! But then without a functional notion of correctness, how can we verify that the neural network works? This problem came up once when researchers were working on **aircraft collision avoidance systems**. At first, they used to use lookup tables with different cases for countless scenarios, but due to the amount of memory of the operations involved, it became appealing to try to use trained neural networks to solve the same problem. But then, how do we *guarantee* that **airplanes do not crash?**.

So, considering this is a serious problem, what are some properties of Deep Neural Networks (DNNs) that we can think about? Some are
- **Safety** - Our network shouldn't do anything undesirable.
- **Privacy** - The network shouldn't *memorise* the training examples.
- **Robustness** - Small changes shouldn't wildly affect the output of the network.
- **Consistency** - Network's predictions are reasonable with what's physically possible.

We can define and study these properties formally! Let us take robustness for example. One way to model it is, "Is there an image classified as a cat by network N, such that the same image with reduced brightness is classified as something else by N?". Now, this can be modelled as an SMT query! How do we go about verifying it? Networks are large in size, and are non-linear activation functions, which means traditional SMT solvers might not work! Let us consider a toy network as below:

``` C
float toy-network(float v11){
	float v21, v22, v31;
	
	v21 = 1.0 * v11;
	if (v21<=0) v21 = 0;
	
	v22 = -1.0 * v11;
	if (v22 <= 0) v22 = 0;
	
	v31 = (1.0*v21 + 1.0 + v22);
	return v31;
}
```

This program represents a simple neural network with one input node and one output node and two hidden nodes with [RELU](https://www.dremio.com/wiki/relu-activation-function/) activation function. Upon converting this program to the SMT-LIB2 format, we may run any SMT solver on it and get the desired proofs.

Now, let us consider Recurrent Neural Networks (RNNs). RNNs have some memory associated with certain nodes which is written to and later read from during the **operation** of the neural network. Since the state gets affected by the input, and the state can affect output, we need to be able to talk about how many times an input is given to the neural network. If we know how many times the RNN will be given inputs, it can be transformed into a Feed Forward Neural Network (FFNN) with equivalent behaviour. In the case of Deep Reinforcement Learning, we can verify the policies by making multiple copies into FFNNs to verify.

Now, considering this techique, what are the problems we face in this method? Active research areas are:
- Minimising DNNs without affecting their functionality
- Abstraction Refinement techniques for verification (can we classify and sacrifice some "irrelevant" functionality?)
- Repairing Networks to follow some formal parameters
- Explainability of DNNs

[Marabou](https://github.com/NeuralNetworkVerification/Marabou) and [NeuralSAT](https://github.com/dynaroars/neuralsat) are tools that have their own implementations for neural network verification.. 

This is a difficult problem, however. Trying to simply use SAT solvers to solve these properties for neural networks can be extremely time consuming. One other approach that was proposed in 2017 was [Reluplex](https://arxiv.org/pdf/1702.01135), which is based on extending the [Simplex](https://en.wikipedia.org/wiki/Simplex_algorithm) method in linear programming to handle FFNNs using RELU activation function, and shows that even verifying simple things about them is NP-complete. Also, since Simplex only works for linear constraints (as it is an algorithm for linear programming), it can only prove properties about the neural network that take the form of linear constraints.  The lecture closely follows the paper from this point on. This approach while simple and not very elegant at first glance, turned out to be much more efficient than SAT solvers for this kind of problem, verifying properties in within a minute which SAT solvers weren't able to in 14400. This is a big deal, especially when the problem is (as the very same paper shows) NP-complete.

That was all for the the day, with the rest to be touched upon in the following day.

# Day 3 <a name="day3"></a>

## Lecture by Kumar Madhukar on Neural Network Verification Part II <a name="dnn2"></a>

### Abstraction Refinement

Today, we explored the strategy of [Abstraction Refinement for Neural Networks](https://arxiv.org/pdf/1910.14574), where we try to analyse if a neural metwork can be replaced by a smaller network. Suppose we have a neural network **N**, we construct  a smaller network **N'**, such that if **N'** violates the specification, so does **N**. If **N'** meets the specification, then all good! If not, there must be a counterexample *x*. Now, if *x* violates the specification for **N** also, then the original neural network violates the specification, and we have proven that it does not. Otherwise (ie. if the counterexample is spurious), we can refine **N'** more to make it more accurate, and "larger". Thus we use the **Counterexample-Guided Abstraction Refinemenet** strategy, where we use counterexamples to either refine the neural network, or prove that a specification does not hold.

Now, let us look at the strategy proposed in the paper deeper. Let us say we have a precondition **P**. postcondition **Q**, and network **N**. A neural network is safe if for every input **x** such that **P(x)** and **Q(N(x))** hold. The paper assumes that
- there is only one output neuron, and only ReLU activation function are used.
- the property of interest is that the output is never greater than some constant

In the transformation, the neural network **N'** is such that **N(x) <= N'(x)**. If **N'** is safe, then so must **N** because of the nature of the postconditiion. Now how do we do construct such a network? We follow the general abstraction-refinement strategy and merging and splitting neurons in an equivalent network **N''**. Now, here is the general strategy -
- If a neuron has only positive outgoing edges,  we classify it as **pos**
- If a neuron has only negative outgoing edges,  we classify it as **neg**
- Otherwise, we split the neuron into two neurons, such that one has all the positive outgoing edges of the original neuron, while the other has all the negative outgoing edges of the original neuron, such that they both have all the incoming edges of the original neuron.

After this is done, all neurons are marked **inc** or **dec**, if increasing the value of the neuron increases the output, and if decrementing the value of the neuron decreases the input. The algorithm for this is as follows -
- The output is marked **inc** (increasing the output increases the output)
- Now, until all neurons are marked
  - All vertices in the layer about to be marked are split, sharing incoming edges, such one neuron only connects to **inc** neurons, and the other only connects to **dec** neurons
  - All neurons with positive weight edges to **inc** neurons, and all neurons with negative weight edges to **dec** neurons are marked **inc**
  - All neurons with positive weight edges to **dec** neurons, and all neurons with negative weight edges to **inc** neurons are marked **dec**

Now after doing all the splitting, we start merging.
- We merge neurons in the same layer. We merge neurons only in with the same pair of **pos/neg** and **inc/dec** tags.
- There are two cases when merging two neurons
  - They share **inc** tags: For every vertex with incoming edges from both the neurons, we sum the edges for the new neuron. For every vertex with outgoing edges to both the neurons, we take the maximum value for the edge of the new neuron. (This will only increase the possible output, preserving **N(x) <= N'(x)**.)
  - They share **dec** tags: For every vertex with incoming edges from both the neurons, we sum the edges for the new neuron. For every vertex with outgoing edges to both the neurons, we take the nimimum value for the edge of the new neuron.  (This will only increase the possible output, preserving **N(x) <= N'(x)**.)
It is possible to show that regardless of the order of merging, we always get the same final neural network by the above algorithm.

Now, this abstraction can be too coarse. If suppose we come across a spurious example (as discussed earlier), we pick a concrete neuron from an absract neuron , and put it back into the network until we come across an abstraction that does not generate spurious examples. (An question: Is the **pos/neg** split really needed? It is also worth thinking about how limiting the constraints on the postcondition and the output layers are, the paper discusses further about this. Go read it!) There are other kinds of refinement techniques too, some which merge two neurons together depending on if they have similar enough inputs, following a k-means clustering strategy.

### Some Hands on Work

Sanya Mittal, a student of Professor Kumar Madhukar, ended the session on neural network verification with an hour long workshop where we explored the verifiers [Marabou](https://github.com/NeuralNetworkVerification/Marabou) and [NeuralSAT](https://github.com/dynaroars/neuralsat). It's hard to reproduce the content covered during the workshop in this format, but do explore these tools on your own! They are extensively documented enough to be useful. Although, before starting to play with them, it might be useful to know what .onnx files are and how to produce them using pytorch.

## Talk by Silvia Ghilezan Proofs as Programming Paradigms: From Logic to AI<a name="lambda"></a>

### The Curry-Howard Isomorphism

*(If the title of this sounds interesting to you, but you the stuff discussed below, you may find this video on [Propositions as Types by Philip Wadler](https://youtu.be/IOiZatlZtGU) useful, appealing, and possibly funny.)*

This was a talk held by [Silvia Ghilezan](https://imft.ftn.uns.ac.rs/silvia/Main) on the correspondence between logical systems and programming languages, and the applications it has in our day to day lives. This correspondence is famously called the **Curry-Howard Isomorphism**. The Curry-Howard isomorphism was stated in reflection of the fact that throughout history, logicians and computer scientists have kept coming up with logical systems and programming languages (or models of computation) that are suspiciously similar. Some such examples are-

- **The Axiomatic System and Combinatory Logic** - The axiomatic system (also referred to as intuitionistic logic) is a system of logic which fixes some axioms, and claims that any object constructed in the system must be from those axioms. For example, the **Peano axiomatisation of natural numbers**. (If one wants to prove anything about natural numbers, they can only do so by constructing proofs with *these axioms* and nothing else.)

    > 
	- There is a natural number 0.
	- Every natural number n has a successor, denoted by Sn.
	- There is no natural number whose successor is 0.
	- Distinct natural numbers have distinct successors.
    - If a property is possessed by 0, and if it is possesed by Sn any given n, then it is possessed by all natural numbers (induction).

The [Combinatory Logic](https://en.wikipedia.org/wiki/Combinatory_logic) is constructed in the same way, as the terms available in it are variables, and only three *primitive functions* (or "combinators") using which all other terms are built.
- **Natural Deduction and The Lambda Calculus** - Natural Deduction is similar to the axiomatic system, except it also allows one to make *assumptions*. If you've taken a course in Discrete Math, you must have come across the method for proving an implication, which tends to go by "Assuming p, we prove q". The lambda calculus corresponds this with the introduction of oh-so familiar (anonymous) functions, which take a single argument (corresponding to the assumption) and contain an expression (corresponding to the right hand size of the implication).

This kind of correspondence has been seen and commented upon throughout history in different shapes and forms-
- In the 1950s, Curry noticed that the types in the combinatory logic correspond to axiomatic schemes in the axiomatic system.
- In 1968, Howard wrote Formulae as Types, writing on this correspondence, formalising the notion, and showing how cut elimination in proofs corresponded to reduction during term evaluation.
- In the 1970s, Lambek showed that intuitionistic proofs and combinatory logic combinators share an equational logic called Cartesian Closed Categories.
- In the 1970s, De Bruijn developed AUTOMATH, a formal system for verifying proofs, the first practical system exploiting the Curry-Howard Isomorphism, being highly influential in the development of proof assistants.
- In the 1970s 1970s Martin-Löf developed the Type Theory, which had constructs for inductive proofs and universal quantifiers too.

Thus, t
- Intuitionistic Logic -> The λ-calculus and Combinatory Logic
- Second-Order Logic -> Polymorphic Lambda Calculus, or [Girard's System F](https://en.wikipedia.org/wiki/System_F) 
- Predicate Logic -> Different Vertices of the [Lambda Cube](https://en.wikipedia.org/wiki/Lambda_cube)
- Classical Logic -> [λμ-calculus](https://en.wikipedia.org/wiki/Lambda-mu_calculus) (Models continuations, which models constructs like async and await.)
- Theory of Communication -> Process Calculi 

Now while all these correspondences between Logical Systems and Theoretical Programming Languages are interesting, especially given how many were discovered independently of each other, how does this have any practical application? Well, when we are dealing with things in computer science, we want to know, "What is computable?". The most famous model of computability is the Turing Machine, and it turns out, that it is *completely* equivalent to the λ-calculus (and also to [Kleene's Recursive Functions](https://en.wikipedia.org/wiki/General_recursive_function).) That is, a function is computable by a computer if and only if it can be expressed as a term of the λ-calculus! (You can replace the constructs in a programming language (assuming it only has natural numbers) with the equivalent λ-calculus terms ant it still works!)

### The Lambda Calculus - A Theory of Functions

Now, what *is* the λ-calculus? It is at its very core, the simplest programming language, built entirely out of functions. Its grammar is below, the first term is variable, the second represents a function application, and the third represents abstraction (or function creation).

$$ M ::= x | (M M) | (\lambda x.M)$$

The λ-calculus has two reduction rules. The first one, also called α-conversion, is simply a renaming rule. It is equivalent to taking a function, and changing the name of the argument while substituting all instances of the argument in the body of the function with that name. The seocnd rule is called β-reduction, and is the process of function application, where upon applying a function, all instances of the argument are substituted with instances of the λ-term that the function is being applied to. (Notice how there is no specification on the *order* of evaluation. If we have a λ-term *(M N)* where both *M* and *N* are β-reducible, then which do we reduce first? Try to convince that yourself that it doesn't matter, and come up with a counterexample otherwise.)


$$ \lambda x.M \rightarrow_{\alpha} \lambda y.M[x:=y], y \not \in FV(M)$$

$$ (\lambda x.M)N \rightarrow_{\beta} M[x:=N]$$

formulae as types

proofs as terms
proofs as programs
proof normalisation as term reduction
cut elimination as termr eduction

Pierce's law is inhabited in mu lambda logic

Intuitionistic logics extended

Proposition Logic
Second-Order proposition Logic
Weakly higher order proposition logic
Higher-Order Proposition Logic
Predicate Logic
Second-order predicate logic
Weakly Higher-Order Logic

Lambda Cube, using order 2, 8 different logic. **A formula is provable in a certain logic if it is well typed in the corresponding type system,**

This is what makes us build proof assitants!

The fundamental theorem of Algebra was proved in CoQ
Proof checking, such as 4 color theorem
Verification - Compcert -> Compiler verification is done in CoQ (If you fly in an airbus, it is verified!)

Properties of the systems in the cube

- Uniqueness of types
- Confluence (Church-Rosser property) -> Order of reduction does not matter
- Type preservation under reduction (Subject Reduction)
- Termination (Stronger Normalisation)
- Expressiveness

Typed programs cannot "go wrong"! Safety = Progress + Preservation

What is the problem of Federated Learning!Federated Learning is a machine learning setting where clients keep training data decentralised between computers, formal verification is anothr communication! Need a common language

PTB-FLA (python testbed for federated learning algorithms)
Communiating Sequential processes calculus (CSP)
Process Analyssi Toolkit Model Checker (PAT

PAPERS!)

Barendregt - Lambda Calculi with Types
WA Howard - Formulae as types notions of Construction
Kastelan - Federated Learning Heneric Algorithms

OPLSS, since 2002 (oregon rpogramming languages)
Proof Society 2024 - International School on proof Theory

## Tutorial by Priyanka Golia by on SAT Solvers Part I (#sat)

### Introduction
Logic is about inferring conclusions from given premises. For very simple things, this is easy. Cats have paws, Fluffy has paws, therefore Fluffy has paws. Others are more complex. Self Driving Cars should stop for Stop signs, but not for broken or damaged ones, how do we reason about when the car should stop? This is not easy to answer as a human, thus we need to have automated reasoning. We also need to reason when we're dealing with racial divisions. How can we formally reason about the system being fair across races or castes?

There was a computer vision model, where given a red framed spectacles, it identified incorrectly. This is a case of a poisoned face recognition system. IMPORTANT QUESTIONS: Is it always the case that S satisfies property P? Hoq often S satisfies P? Why doesn't S satisfy P? We use SAT and SMT solvers. Now, these are very hard problems, how do we solve this in NP time?


**Satisfiability** - Given a Boolean formula, is there a solution? Assignment of 0's and 1's to the variables that makes the formula equal 1/

$$F(X) = (x_1 \lor x_2) \land (\x)$$ type out all pairssss

SAT Solvers -> if a formula is SAT, gives a satisfying assignment -> Boolean theory
SMT -> Formulas in different theories -> Linear integer arithmetic, Linear real arithmetic, bit vectors, strings


Basic of propositional logic, constraint encoding (if time permits)
How does SAT solver work and what makes them fast.

All Greeks are human, all humans are mortal, and all greeks are mortal. Can we say the same about: Not all greeks are human, not all humans are mortal, not all greeks are mortal?

Now, writing statements all the time isn't useful. To be able to talk about logical systems, we need to use symbolic variables.

Lets assume that $$\tau$$ is a function that maps variables of a propositional formula to {0,1}. There are 2 to the power of n possible n-tuples which can be apssed as arguments which. Tau satisfies if F(tau) = 1. F is satisfiable if there exists such a tau. It is valid if it is 1 for every f. If it is 0 for every, then unsatisfiable.

Set of all satisfying assignment of F is alled models, models(F)= {tau such that F(tau) = 1}
Models of negation of F = 2 to the variables - Models(F)
Models of (F or G) = Models(F) union Models(G)
And = Intersection

Two formulae are equivalent if they have the same models

SAT solvers take inputs in Conjunction Normal Form (ANDs of ORs). This is because doing reasoning abou t them is easy, and every propositional formula is reducible to CNF form.
(x1 AND y1) OR (x2 AND y2)...
Inverse CNF, converting to CNF takes 2^n

Can we better?

There exist equisatisfiable formulae like F=(p OR alpha) AND (NOT p OR beta), G = (alpha AND beta)
F and G are equisatisfiable. F is satisfiable if and only if G is satisfiable.

Now, we can do better than 2^n with just 3 variables.

If we assign a new variable for each clause, and add double implication clauses, the original gets reduced to one clause, while the new double implications get converted to three terms.
Thus, we have 3n + 1, which is must better!!!!

Every formula F can be represented in CNF, say Fcnf in polynomyal time such that F is satisfiable if and only if Fcnf is satisfiable. Do we really need both directions?

K Sat is with K different literals in each clause. 2 Sat can be solved in poly times, but we dont know for 3 SAT!!!

Convert 4 SAT into 3 SAT. Can you do the same for 3 SAT for 2 SAT.

Now we come to Constraint Encoding.

How do encode Graph Colouring as a SAT problem?


Write your solution here!!!!! 9 variables will be required.
